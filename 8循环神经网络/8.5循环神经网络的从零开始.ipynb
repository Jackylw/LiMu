{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-14T01:34:56.584180Z",
     "start_time": "2025-10-14T01:34:52.585393Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:35:37.996600Z",
     "start_time": "2025-10-14T01:35:37.966496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 独热编码\n",
    "F.one_hot(torch.tensor([0, 2]), len(vocab))"
   ],
   "id": "ae7c3b3ef1e1c928",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:36:11.020964Z",
     "start_time": "2025-10-14T01:36:10.974503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = torch.arange(10).reshape((2, 5))\n",
    "F.one_hot(X.T, 28).shape"
   ],
   "id": "2fd59885d2469005",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:38:00.256784Z",
     "start_time": "2025-10-14T01:38:00.252170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 初始化模型参数\n",
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device) * 0.01\n",
    "\n",
    "    # 隐藏层参数\n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    # 输出层参数\n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    # 附加梯度\n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad_(True)\n",
    "    return params"
   ],
   "id": "501691f486d835d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:38:57.044136Z",
     "start_time": "2025-10-14T01:38:57.040460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 循环神经网络模型\n",
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device), )"
   ],
   "id": "d4c75634f1b2ba69",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:39:00.136384Z",
     "start_time": "2025-10-14T01:39:00.133509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rnn(inputs, state, params):\n",
    "    # inputs的形状：(时间步数量，批量大小，词表大小)\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    # X的形状：(批量大小，词表大小)\n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ],
   "id": "171b6e89312fb080",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:40:36.166399Z",
     "start_time": "2025-10-14T01:40:36.162987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class RNNModelScratch: #@save\n",
    "    \"\"\"从零开始实现的循环神经网络模型\"\"\"\n",
    "    def __init__(self, vocab_size, num_hiddens, device,\n",
    "                 get_params, init_state, forward_fn):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "\n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "\n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ],
   "id": "ddd1816a33c65901",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:40:49.730844Z",
     "start_time": "2025-10-14T01:40:49.139880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], d2l.try_gpu())\n",
    "Y, new_state = net(X.to(d2l.try_gpu()), state)\n",
    "Y.shape, len(new_state), new_state[0].shape"
   ],
   "id": "83366b7f779951c0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/ptcu118/lib/python3.9/site-packages/torch/cuda/__init__.py:287: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Ti Laptop GPU with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_37 sm_90.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Ti Laptop GPU GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m num_hiddens \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m512\u001B[39m\n\u001B[0;32m----> 2\u001B[0m net \u001B[38;5;241m=\u001B[39m \u001B[43mRNNModelScratch\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_hiddens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md2l\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtry_gpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                      \u001B[49m\u001B[43minit_rnn_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrnn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m state \u001B[38;5;241m=\u001B[39m net\u001B[38;5;241m.\u001B[39mbegin_state(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], d2l\u001B[38;5;241m.\u001B[39mtry_gpu())\n\u001B[1;32m      5\u001B[0m Y, new_state \u001B[38;5;241m=\u001B[39m net(X\u001B[38;5;241m.\u001B[39mto(d2l\u001B[38;5;241m.\u001B[39mtry_gpu()), state)\n",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m, in \u001B[0;36mRNNModelScratch.__init__\u001B[0;34m(self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, vocab_size, num_hiddens, device,\n\u001B[1;32m      4\u001B[0m              get_params, init_state, forward_fn):\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_hiddens \u001B[38;5;241m=\u001B[39m vocab_size, num_hiddens\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams \u001B[38;5;241m=\u001B[39m \u001B[43mget_params\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocab_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_hiddens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_state, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward_fn \u001B[38;5;241m=\u001B[39m init_state, forward_fn\n",
      "Cell \u001B[0;32mIn[4], line 9\u001B[0m, in \u001B[0;36mget_params\u001B[0;34m(vocab_size, num_hiddens, device)\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mrandn(size\u001B[38;5;241m=\u001B[39mshape, device\u001B[38;5;241m=\u001B[39mdevice) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# 隐藏层参数\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m W_xh \u001B[38;5;241m=\u001B[39m \u001B[43mnormal\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_hiddens\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m W_hh \u001B[38;5;241m=\u001B[39m normal((num_hiddens, num_hiddens))\n\u001B[1;32m     11\u001B[0m b_h \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(num_hiddens, device\u001B[38;5;241m=\u001B[39mdevice)\n",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m, in \u001B[0;36mget_params.<locals>.normal\u001B[0;34m(shape)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mnormal\u001B[39m(shape):\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandn\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.01\u001B[39m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:43:15.910704Z",
     "start_time": "2025-10-14T01:43:15.903313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 预测\n",
    "def predict_ch8(prefix, num_preds, net, vocab, device):  #@save\n",
    "    \"\"\"在prefix后面生成新字符\"\"\"\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1, 1))\n",
    "    for y in prefix[1:]:  # 预热期\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    for _ in range(num_preds):  # 预测num_preds步\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ],
   "id": "c381373aebd45a41",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:43:20.623316Z",
     "start_time": "2025-10-14T01:43:20.607895Z"
    }
   },
   "cell_type": "code",
   "source": "predict_ch8('time traveller ', 10, net, vocab, d2l.try_gpu())",
   "id": "dccfbcf9e965d75f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m predict_ch8(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime traveller \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[43mnet\u001B[49m, vocab, d2l\u001B[38;5;241m.\u001B[39mtry_gpu())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'net' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:43:56.373662Z",
     "start_time": "2025-10-14T01:43:56.368125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 梯度裁剪\n",
    "def grad_clipping(net, theta):  #@save\n",
    "    \"\"\"裁剪梯度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        params = [p for p in net.parameters() if p.requires_grad]\n",
    "    else:\n",
    "        params = net.params\n",
    "    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ],
   "id": "b1fff1f1265afff5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:44:09.535873Z",
     "start_time": "2025-10-14T01:44:09.527425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练\n",
    "#@save\n",
    "def train_epoch_ch8(net, train_iter, loss, updater, device, use_random_iter):\n",
    "    \"\"\"训练网络一个迭代周期（定义见第8章）\"\"\"\n",
    "    state, timer = None, d2l.Timer()\n",
    "    metric = d2l.Accumulator(2)  # 训练损失之和,词元数量\n",
    "    for X, Y in train_iter:\n",
    "        if state is None or use_random_iter:\n",
    "            # 在第一次迭代或使用随机抽样时初始化state\n",
    "            state = net.begin_state(batch_size=X.shape[0], device=device)\n",
    "        else:\n",
    "            if isinstance(net, nn.Module) and not isinstance(state, tuple):\n",
    "                # state对于nn.GRU是个张量\n",
    "                state.detach_()\n",
    "            else:\n",
    "                # state对于nn.LSTM或对于我们从零开始实现的模型是个张量\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "        y = Y.T.reshape(-1)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat, state = net(X, state)\n",
    "        l = loss(y_hat, y.long()).mean()\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            updater.step()\n",
    "        else:\n",
    "            l.backward()\n",
    "            grad_clipping(net, 1)\n",
    "            # 因为已经调用了mean函数\n",
    "            updater(batch_size=1)\n",
    "        metric.add(l * y.numel(), y.numel())\n",
    "    return math.exp(metric[0] / metric[1]), metric[1] / timer.stop()"
   ],
   "id": "aaba594f15cba80f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:44:12.774741Z",
     "start_time": "2025-10-14T01:44:12.770696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@save\n",
    "def train_ch8(net, train_iter, vocab, lr, num_epochs, device,\n",
    "              use_random_iter=False):\n",
    "    \"\"\"训练模型（定义见第8章）\"\"\"\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='perplexity',\n",
    "                            legend=['train'], xlim=[10, num_epochs])\n",
    "    # 初始化\n",
    "    if isinstance(net, nn.Module):\n",
    "        updater = torch.optim.SGD(net.parameters(), lr)\n",
    "    else:\n",
    "        updater = lambda batch_size: d2l.sgd(net.params, lr, batch_size)\n",
    "    predict = lambda prefix: predict_ch8(prefix, 50, net, vocab, device)\n",
    "    # 训练和预测\n",
    "    for epoch in range(num_epochs):\n",
    "        ppl, speed = train_epoch_ch8(\n",
    "            net, train_iter, loss, updater, device, use_random_iter)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(predict('time traveller'))\n",
    "            animator.add(epoch + 1, [ppl])\n",
    "    print(f'困惑度 {ppl:.1f}, {speed:.1f} 词元/秒 {str(device)}')\n",
    "    print(predict('time traveller'))\n",
    "    print(predict('traveller'))"
   ],
   "id": "3cf18aeb3f748486",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T01:44:19.139961Z",
     "start_time": "2025-10-14T01:44:19.121787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs, lr = 500, 1\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu())"
   ],
   "id": "92739c988f99c887",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m num_epochs, lr \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m500\u001B[39m, \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m----> 2\u001B[0m train_ch8(\u001B[43mnet\u001B[49m, train_iter, vocab, lr, num_epochs, d2l\u001B[38;5;241m.\u001B[39mtry_gpu())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'net' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "net = RNNModelScratch(len(vocab), num_hiddens, d2l.try_gpu(), get_params,\n",
    "                      init_rnn_state, rnn)\n",
    "train_ch8(net, train_iter, vocab, lr, num_epochs, d2l.try_gpu(),\n",
    "          use_random_iter=True)"
   ],
   "id": "c36e9dd51c6dc43b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
