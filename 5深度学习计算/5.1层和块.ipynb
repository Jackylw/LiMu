{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-09T02:51:10.474714Z",
     "start_time": "2025-10-09T02:51:10.434084Z"
    }
   },
   "source": [
    "# 256个单元和ReLU激活函数的全连接隐藏层\n",
    "# 10个隐藏单元且不带激活函数的全连接输出层\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "print(net(X))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0759,  0.0107, -0.0891, -0.2265,  0.1724, -0.1336, -0.3103,  0.2736,\n",
      "          0.1038,  0.0267],\n",
      "        [-0.1002,  0.0119,  0.0412, -0.2588,  0.0451,  0.0411, -0.3298,  0.3297,\n",
      "          0.1116, -0.0536]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 自定义块\n",
    "- 将输入数据作为其前向传播函数的参数。\n",
    "- 通过前向传播函数来生成输出。请注意，输出的形状可能与输入的形状不同。例如，我们上面模型中的第一个全连接的层接收一个20维的输入，但是返回一个维度为256的输出。\n",
    "- 计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的。\n",
    "- 存储和访问前向传播计算所需的参数。\n",
    "- 根据需要初始化模型参数。"
   ],
   "id": "91867245071b499d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T03:01:10.600049Z",
     "start_time": "2025-10-09T03:01:10.596658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    # 定义模型参数\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256) # 隐藏层\n",
    "        self.out = nn.Linear(256, 10) # 输出层\n",
    "\n",
    "    # 定义前向传播\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))\n",
    "        return self.out(x)"
   ],
   "id": "587b0e7b443aa8be",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T03:16:58.065626Z",
     "start_time": "2025-10-09T03:16:58.058095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = MLP()\n",
    "print(net(X))"
   ],
   "id": "9b745536f8fecc75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0442, -0.2290, -0.0032, -0.0274,  0.3919, -0.4117,  0.0994,  0.2953,\n",
      "         -0.0011,  0.2677],\n",
      "        [-0.0523, -0.2698,  0.0801, -0.1697,  0.2817, -0.2492, -0.0771,  0.2785,\n",
      "         -0.1075,  0.2445]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 顺序块\n",
    "函数定义\n",
    "- 一种将块逐个追加到列表中的函数\n",
    "- 一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”"
   ],
   "id": "6ce861e869fcebc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T03:23:06.987654Z",
     "start_time": "2025-10-09T03:23:06.984010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module的子类实例。我们把它保存在\n",
    "            # `Module`的成员变量_modules中。_modules是一个OrderDict。\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ],
   "id": "ba1c5aa96983c064",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T03:24:39.107495Z",
     "start_time": "2025-10-09T03:24:39.102419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "print(net(X))"
   ],
   "id": "1dc97b0550ad1606",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1303,  0.0178, -0.3992, -0.0673, -0.0826,  0.0270,  0.0585, -0.0910,\n",
      "         -0.1943,  0.0495],\n",
      "        [-0.1409,  0.0918, -0.2794, -0.0091, -0.1363, -0.0077,  0.1068,  0.0318,\n",
      "         -0.2367, -0.0792]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ab0a516afcde847"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
